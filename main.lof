\babel@toc {ngerman}{}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Representation of a sugar beet plant}}{14}{figure.caption.5}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Validation and training loss curve}}{22}{figure.caption.8}% 
\contentsline {figure}{\numberline {2.2}{\ignorespaces Real Example of the Validation and training loss curve}}{23}{figure.caption.9}% 
\contentsline {figure}{\numberline {2.3}{\ignorespaces Real Example of the Validation and training loss curve}}{23}{figure.caption.10}% 
\contentsline {figure}{\numberline {2.4}{\ignorespaces Overview of the architecture of Alexnet}}{24}{figure.caption.11}% 
\contentsline {figure}{\numberline {2.5}{\ignorespaces Overview of the various architecture for VGG}}{25}{figure.caption.12}% 
\contentsline {figure}{\numberline {2.6}{\ignorespaces Residual learning: a building block}}{26}{figure.caption.13}% 
\contentsline {figure}{\numberline {2.7}{\ignorespaces Overview of the Resnet Architecture}}{27}{figure.caption.14}% 
\contentsline {figure}{\numberline {2.8}{\ignorespaces Trend in publications about Deep Learning}}{28}{figure.caption.15}% 
\contentsline {figure}{\numberline {2.9}{\ignorespaces Differences between how DNNs and humans recognize objects}}{30}{figure.caption.16}% 
\contentsline {figure}{\numberline {2.10}{\ignorespaces Illustrating the difference between aleatoric and epistemic uncertainty}}{31}{figure.caption.17}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Example of use for the function \textit {clock()}\relax }}{36}{figure.caption.18}% 
\contentsline {figure}{\numberline {3.2}{\ignorespaces Synopsis of the command \textit {time}\relax }}{36}{figure.caption.19}% 
\contentsline {figure}{\numberline {3.3}{\ignorespaces Program used to test the command \textit {time}\relax }}{37}{figure.caption.20}% 
\contentsline {figure}{\numberline {3.4}{\ignorespaces Disable turbo boost in both AMD and Intel devices\relax }}{38}{figure.caption.21}% 
\contentsline {figure}{\numberline {3.5}{\ignorespaces Disable Hyper-Threading\relax }}{39}{figure.caption.22}% 
\contentsline {figure}{\numberline {3.6}{\ignorespaces Set the scaling governor policy to be \textit {performance} for every cpu\relax }}{39}{figure.caption.23}% 
\contentsline {figure}{\numberline {3.7}{\ignorespaces Wrong benchmark for inference time}}{41}{figure.caption.24}% 
\contentsline {figure}{\numberline {3.8}{\ignorespaces Correct way to measure inference\relax }}{42}{figure.caption.25}% 
\contentsline {figure}{\numberline {3.9}{\ignorespaces Run benchmark on android with Tensorflow Lite}}{42}{figure.caption.26}% 
\contentsline {figure}{\numberline {3.10}{\ignorespaces Command to access the inference in Tensorflow Lite}}{42}{figure.caption.27}% 
\contentsline {figure}{\numberline {3.11}{\ignorespaces Architecture of the convolutional neural network used as an example to calculate inference time}}{44}{figure.caption.28}% 
\contentsline {figure}{\numberline {3.12}{\ignorespaces Benchmark for training time\relax }}{46}{figure.caption.30}% 
\contentsline {figure}{\numberline {3.13}{\ignorespaces Fastai calculation for accuracy \cite {fastaidocs}\relax }}{46}{figure.caption.31}% 
\contentsline {figure}{\numberline {3.14}{\ignorespaces Behaviour of the benchmarking suite on a conceptual level\relax }}{46}{figure.caption.32}% 
\contentsline {figure}{\numberline {3.15}{\ignorespaces Example of graphs produced by the tool when analysing training time\relax }}{49}{figure.caption.34}% 
\contentsline {figure}{\numberline {3.16}{\ignorespaces Example of the graphs produced by the tool when analysing inference time\relax }}{49}{figure.caption.35}% 
\contentsline {figure}{\numberline {3.17}{\ignorespaces Overview of the process to test inference\relax }}{50}{figure.caption.36}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Comparison between epoch/accuracy for each model}}{55}{figure.caption.39}% 
\contentsline {figure}{\numberline {4.2}{\ignorespaces Comparison between training time/accuracy for each model}}{56}{figure.caption.40}% 
\contentsline {figure}{\numberline {4.3}{\ignorespaces Accuracy of Alexnet and Resnet152 against training time in seconds\relax }}{56}{figure.caption.41}% 
\contentsline {figure}{\numberline {4.4}{\ignorespaces Accuracy of Resnet101 and VGG9 against training time in seconds\relax }}{57}{figure.caption.42}% 
\contentsline {figure}{\numberline {4.5}{\ignorespaces Breaking point of Resnet101 and VGG19\relax }}{57}{figure.caption.43}% 
\contentsline {figure}{\numberline {4.6}{\ignorespaces Comparison between training time and accuracy for each model for 10 epochs}}{58}{figure.caption.44}% 
\contentsline {figure}{\numberline {4.7}{\ignorespaces Comparison between training time and accuracy for each model for 100 epochs}}{59}{figure.caption.45}% 
\contentsline {figure}{\numberline {4.8}{\ignorespaces Training loss and validity loss of all models calculated over 100 epochs\relax }}{59}{figure.caption.47}% 
\contentsline {figure}{\numberline {4.9}{\ignorespaces Inference time measured for each model}}{60}{figure.caption.48}% 
\contentsline {figure}{\numberline {4.10}{\ignorespaces Inference time measured for model Resnet18 and Alexnet\relax }}{61}{figure.caption.49}% 
\contentsline {figure}{\numberline {4.11}{\ignorespaces Size of the images over inference time}}{61}{figure.caption.50}% 
\contentsline {figure}{\numberline {4.12}{\ignorespaces Inference time measured for model Resnet18 and Alexnet\relax }}{62}{figure.caption.51}% 
\contentsline {figure}{\numberline {4.13}{\ignorespaces Inference time measured for model Resnet18 and Alexnet\relax }}{62}{figure.caption.52}% 
\contentsline {figure}{\numberline {4.14}{\ignorespaces Accuracy achieved when training for 100 epochs}}{64}{figure.caption.55}% 
\contentsline {figure}{\numberline {4.15}{\ignorespaces Accuracy achieved when training for 100 epochs in relation with training time}}{65}{figure.caption.56}% 
\contentsline {figure}{\numberline {4.16}{\ignorespaces Training loss and validation loss of all models calculated over 100 epochs\relax }}{65}{figure.caption.57}% 
\contentsline {figure}{\numberline {4.17}{\ignorespaces Training loss and validation loss of Resnet101 and Resnet152 over 100 epochs\relax }}{66}{figure.caption.59}% 
\contentsline {figure}{\numberline {4.18}{\ignorespaces Inference time measured for each model}}{67}{figure.caption.60}% 
\contentsline {figure}{\numberline {4.19}{\ignorespaces Inference time measured for Resnet101 and Resnet152}}{67}{figure.caption.61}% 
\contentsline {figure}{\numberline {4.20}{\ignorespaces Size of the images over inference time for the seedlings dataset}}{68}{figure.caption.62}% 
\contentsline {figure}{\numberline {4.21}{\ignorespaces Training loss and validation loss of Resnet101 and Resnet152 over 100 epochs on the 'plant\_seedlings\_v2' dataset and the gray-scale pictures\relax }}{70}{figure.caption.65}% 
\contentsline {figure}{\numberline {4.22}{\ignorespaces Inference time of each model trained with grey images as well}}{71}{figure.caption.66}% 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {A.1}{\ignorespaces Histogram of the slowest files in common amongst all models\relax }}{83}{figure.caption.68}% 
\contentsline {figure}{\numberline {A.2}{\ignorespaces Example of the architecture of residual networks}}{84}{figure.caption.69}% 
\contentsline {figure}{\numberline {A.3}{\ignorespaces Histogram of the fastest files of Resnet 152\relax }}{85}{figure.caption.70}% 
\contentsline {figure}{\numberline {A.4}{\ignorespaces Histogram of the slowest files of Resnet152\relax }}{86}{figure.caption.71}% 
\contentsline {figure}{\numberline {A.5}{\ignorespaces Complete result of the test for inference time in the seedlings dataset\relax }}{87}{figure.caption.72}% 
\contentsline {figure}{\numberline {A.6}{\ignorespaces Complete result of the test for inference time in the seedlings dataset with grey images\relax }}{88}{figure.caption.73}% 
\contentsline {figure}{\numberline {A.7}{\ignorespaces Complete result of the test for inference time in the seedlings dataset with grey images. The inference here is calculated by feeding grey scale images to the models\relax }}{89}{figure.caption.74}% 
