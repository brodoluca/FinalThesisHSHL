\babel@toc {ngerman}{}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Representation of a sugar beet plant}}{14}{figure.caption.5}% 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Trend in publications about Deep Learning}}{19}{figure.caption.6}% 
\contentsline {figure}{\numberline {3.2}{\ignorespaces Differences between how DNNs and humans recognize objects}}{21}{figure.caption.7}% 
\contentsline {figure}{\numberline {3.3}{\ignorespaces Illustrating the difference between aleatoric and epistemic uncertainty}}{22}{figure.caption.8}% 
\contentsline {figure}{\numberline {3.4}{\ignorespaces Validation and training loss curve}}{28}{figure.caption.10}% 
\contentsline {figure}{\numberline {3.5}{\ignorespaces Real Example of the Validation and training loss curve}}{29}{figure.caption.11}% 
\contentsline {figure}{\numberline {3.6}{\ignorespaces Real Example of the Validation and training loss curve}}{30}{figure.caption.12}% 
\contentsline {figure}{\numberline {3.7}{\ignorespaces Overview of the architecture of Alexnet}}{31}{figure.caption.13}% 
\contentsline {figure}{\numberline {3.8}{\ignorespaces Overview of the various architecture for VGG}}{32}{figure.caption.14}% 
\contentsline {figure}{\numberline {3.9}{\ignorespaces Residual learning: a building block}}{32}{figure.caption.15}% 
\contentsline {figure}{\numberline {3.10}{\ignorespaces Overview of the Resnet Architecture}}{33}{figure.caption.16}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Example of use for the function \textit {clock()}\relax }}{38}{figure.caption.17}% 
\contentsline {figure}{\numberline {4.2}{\ignorespaces Synopsis of the command \textit {time}\relax }}{38}{figure.caption.18}% 
\contentsline {figure}{\numberline {4.3}{\ignorespaces Program used to test the command \textit {time}\relax }}{39}{figure.caption.19}% 
\contentsline {figure}{\numberline {4.4}{\ignorespaces Disable turbo boost in both AMD and Intel devices\relax }}{40}{figure.caption.20}% 
\contentsline {figure}{\numberline {4.5}{\ignorespaces Disable Hyper-Threading\relax }}{41}{figure.caption.21}% 
\contentsline {figure}{\numberline {4.6}{\ignorespaces Set the scaling governor policy to be \textit {performance} for every cpu\relax }}{41}{figure.caption.22}% 
\contentsline {figure}{\numberline {4.7}{\ignorespaces Wrong benchmark for inference time}}{42}{figure.caption.23}% 
\contentsline {figure}{\numberline {4.8}{\ignorespaces Correct way to measure inference\relax }}{43}{figure.caption.24}% 
\contentsline {figure}{\numberline {4.9}{\ignorespaces Run benchmark on android with Tensorflow Lite}}{43}{figure.caption.25}% 
\contentsline {figure}{\numberline {4.10}{\ignorespaces Command to access the inference in Tensorflow Lite}}{43}{figure.caption.26}% 
\contentsline {figure}{\numberline {4.11}{\ignorespaces Architecture of the convolutional neural network used as an example to calculate inference time}}{45}{figure.caption.27}% 
\contentsline {figure}{\numberline {4.12}{\ignorespaces Benchmark for training time\relax }}{47}{figure.caption.29}% 
\contentsline {figure}{\numberline {4.13}{\ignorespaces Fastai calculation for accuracy \cite {fastaidocs}\relax }}{47}{figure.caption.30}% 
\contentsline {figure}{\numberline {4.14}{\ignorespaces Behaviour of the benchmarking suite on a conceptual level\relax }}{47}{figure.caption.31}% 
\contentsline {figure}{\numberline {4.15}{\ignorespaces Example of graphs produced by the tool when analysing training time\relax }}{50}{figure.caption.33}% 
\contentsline {figure}{\numberline {4.16}{\ignorespaces Example of the graphs produced by the tool when analysing inference time\relax }}{50}{figure.caption.34}% 
\contentsline {figure}{\numberline {4.17}{\ignorespaces Overview of the process to test inference\relax }}{51}{figure.caption.35}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Accuracy achieved when training for 100 epochs}}{55}{figure.caption.38}% 
\contentsline {figure}{\numberline {5.2}{\ignorespaces Accuracy achieved when training for 100 epochs in relation with training time}}{56}{figure.caption.40}% 
\contentsline {figure}{\numberline {5.3}{\ignorespaces Training loss and validation loss of all models calculated over 100 epochs\relax }}{56}{figure.caption.41}% 
\contentsline {figure}{\numberline {5.4}{\ignorespaces Training loss and validation loss of Resnet101 and Resnet152 over 100 epochs\relax }}{57}{figure.caption.43}% 
\contentsline {figure}{\numberline {5.5}{\ignorespaces Inference time measured for each model}}{58}{figure.caption.44}% 
\contentsline {figure}{\numberline {5.6}{\ignorespaces Inference time measured for Resnet101 and Resnet152}}{59}{figure.caption.45}% 
\contentsline {figure}{\numberline {5.7}{\ignorespaces Size of the images over inference time for the seedlings dataset}}{60}{figure.caption.46}% 
\contentsline {figure}{\numberline {5.8}{\ignorespaces Training loss and validation loss of Resnet101 and Resnet152 over 100 epochs on the 'plant\_seedlings\_v2' dataset and the gray-scale pictures\relax }}{61}{figure.caption.49}% 
\contentsline {figure}{\numberline {5.9}{\ignorespaces Inference time of each model trained with grey images as well}}{62}{figure.caption.50}% 
\contentsline {figure}{\numberline {5.10}{\ignorespaces Comparison between epoch/accuracy for each model}}{63}{figure.caption.51}% 
\contentsline {figure}{\numberline {5.11}{\ignorespaces Comparison between training time/accuracy for each model}}{63}{figure.caption.52}% 
\contentsline {figure}{\numberline {5.12}{\ignorespaces Accuracy of Alexnet and Resnet152 against training time in seconds\relax }}{64}{figure.caption.53}% 
\contentsline {figure}{\numberline {5.13}{\ignorespaces Accuracy of Resnet101 and VGG9 against training time in seconds\relax }}{64}{figure.caption.54}% 
\contentsline {figure}{\numberline {5.14}{\ignorespaces Breaking point of Resnet101 and VGG19\relax }}{65}{figure.caption.55}% 
\contentsline {figure}{\numberline {5.15}{\ignorespaces Comparison between training time and accuracy for each model for 10 epochs}}{66}{figure.caption.56}% 
\contentsline {figure}{\numberline {5.16}{\ignorespaces Comparison between training time and accuracy for each model for 100 epochs}}{67}{figure.caption.57}% 
\contentsline {figure}{\numberline {5.17}{\ignorespaces Training loss and validity loss of all models calculated over 100 epochs\relax }}{67}{figure.caption.59}% 
\contentsline {figure}{\numberline {5.18}{\ignorespaces Inference time measured for each model}}{68}{figure.caption.60}% 
\contentsline {figure}{\numberline {5.19}{\ignorespaces Inference time measured for model Resnet18 and Alexnet\relax }}{68}{figure.caption.61}% 
\contentsline {figure}{\numberline {5.20}{\ignorespaces Size of the images over inference time}}{69}{figure.caption.62}% 
\contentsline {figure}{\numberline {5.21}{\ignorespaces Inference time measured for model Resnet18 and Alexnet\relax }}{70}{figure.caption.63}% 
\contentsline {figure}{\numberline {5.22}{\ignorespaces Inference time measured for model Resnet18 and Alexnet\relax }}{70}{figure.caption.64}% 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {A.1}{\ignorespaces Histogram of the slowest files in common amongst all models\relax }}{85}{figure.caption.67}% 
\contentsline {figure}{\numberline {A.2}{\ignorespaces Example of the architecture of residual networks}}{86}{figure.caption.68}% 
\contentsline {figure}{\numberline {A.3}{\ignorespaces Histogram of the fastest files of Resnet 152\relax }}{87}{figure.caption.69}% 
\contentsline {figure}{\numberline {A.4}{\ignorespaces Histogram of the slowest files of Resnet152\relax }}{88}{figure.caption.70}% 
\contentsline {figure}{\numberline {A.5}{\ignorespaces Complete result of the test for inference time in the seedlings dataset\relax }}{89}{figure.caption.71}% 
\contentsline {figure}{\numberline {A.6}{\ignorespaces Complete result of the test for inference time in the seedlings dataset with grey images\relax }}{90}{figure.caption.72}% 
\contentsline {figure}{\numberline {A.7}{\ignorespaces Complete result of the test for inference time in the seedlings dataset with grey images. The inference here is calculated by feeding grey scale images to the models\relax }}{91}{figure.caption.73}% 
